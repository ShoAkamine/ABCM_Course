{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1bbdce",
   "metadata": {},
   "source": [
    "# ABCM Computer lab 1: Social coordination & Theory of mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b099f",
   "metadata": {},
   "source": [
    "In this computer lab, we will use the tomsup package created by Waade et al. (2022) to simulate various Game Theory games between agents that have varying levels of theory of mind (or other strategies).\n",
    "\n",
    "All exercises are indicated with an **Exercise _N_** header. The notebook also contains some explanation, which is also interleaved with small coding exercises (of the form _\"In the code cell below, do X\"_) which help you understand how the code works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714eb7f",
   "metadata": {},
   "source": [
    "First, install the ```tomsup``` package by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c6f817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T06:38:54.257548Z",
     "start_time": "2022-09-20T06:38:50.770400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tomsup in /Users/U968195/anaconda3/lib/python3.7/site-packages (1.1.7)\n",
      "Requirement already satisfied: numpy>=1.2.4 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.0.1 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (1.1.0)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (0.11.2)\n",
      "Requirement already satisfied: wasabi<0.10.0,>=0.8.2 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (0.9.1)\n",
      "Requirement already satisfied: matplotlib>=3.4.2 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (3.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (1.7.1)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from tomsup) (1.3.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.4.2->tomsup) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.4.2->tomsup) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.4.2->tomsup) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.4.2->tomsup) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.4.2->tomsup) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from pandas>=1.2.3->tomsup) (2022.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/U968195/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.4.2->tomsup) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/U968195/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.2->tomsup) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tomsup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527b109",
   "metadata": {},
   "source": [
    "Now, let's do the necessary imports by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78d8d187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T06:39:37.673425Z",
     "start_time": "2022-09-20T06:39:37.666728Z"
    }
   },
   "outputs": [],
   "source": [
    "import tomsup as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a3544",
   "metadata": {},
   "source": [
    "## Exploring the games in tomsup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c0611",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Use the command ```help(ts.PayoffMatrix)``` (see page 11 of Waade et al., 2022) to explore what Game Theory games are pre-specified in the tomsup package. Print and investigate each of these pay-off matrices. For each one: Write down whether they are competitive or cooperative in nature. Also explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee86ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e98c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef68af71",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4501a6c",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "```penny_competitive``` is an example of a zero-sum game. The definition of a zero-sum game is as follows:\n",
    "\"games in which choices by players can neither increase nor decrease the available resources. In zero-sum games, the total benefit that goes to all players in a game, for every combination of strategies, always adds to zero (more informally, a player benefits only at the equal expense of others)\"\n",
    "Can you find any other example of a zero-sum game among the predefined games in the tomsup package?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa459a97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ea3685a",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "```prisoners_dilemma``` is an example of a game that has a Nash equilibrium that is suboptimal for both agents. That is, when both agents decide to betray each other (i.e, both choose action 0), they are worse off than if they both remain silent (i,e., both choose action 1). However, if they are in a state where they both choose action 0, neither agent can improve their own pay-off by changing strategy, making this state a Nash equilibrium. Can you find any other games among the predefined games that have such a Nash equilibrium that is suboptimal for both agents? If so, explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbcbb8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86aea48",
   "metadata": {},
   "source": [
    "## Running interactions between agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac76559",
   "metadata": {},
   "source": [
    "### Creating a game:\n",
    "A game can be created using the ```PayoffMatrix``` class, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed02765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T06:50:28.984643Z",
     "start_time": "2022-09-20T06:50:28.982202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Class PayoffMatrix, Name = penny_competitive> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 | -1 |  1 |\n",
      "agent 0|  1 |  1 | -1 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  1 | -1 |\n",
      "agent 0|  1 | -1 |  1 |\n",
      " \n"
     ]
    }
   ],
   "source": [
    "penny = ts.PayoffMatrix(name='penny_competitive')\n",
    "\n",
    "print(penny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e05779",
   "metadata": {},
   "source": [
    "Try this in the code cell below by creating a staghunt game and printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3aad74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e26568",
   "metadata": {},
   "source": [
    "### Creating a group of agents:\n",
    "\n",
    "A group of agents can be created quickly, using the ```create_agents()``` function. This function takes two input arguments:\n",
    "1. ```agents```: specifies the agent types in the group. Possible agent types are:\n",
    "    - 'RB'\n",
    "    - 'QL'\n",
    "    - 'WSLS'\n",
    "    - '1-TOM'\n",
    "    - '2-TOM'\n",
    "2. ```start_params```: specifies the starting parameters for each agent. An empty dictionary {}, denoted by ```{}``` gives default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10b5e615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T07:06:47.970039Z",
     "start_time": "2022-09-20T07:06:47.966828Z"
    }
   },
   "outputs": [],
   "source": [
    "starting_parameters = [{'bias':0.7}, {'learning_rate':0.5}, {}, {}, {}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b93b52",
   "metadata": {},
   "source": [
    "In the code cell below, use the ```create_agents()``` function to create an object of the ```AgentGroup``` class, which you assign to a variable called ```group```.\n",
    "Use the following input arguments:\n",
    "1. Create a list called ```agent_types``` which contains all possible agent types names as listed above. Pass that as the ```agents``` argument\n",
    "2. Create a list called ```starting_parameters``` which contains:\n",
    "    - ```{'bias':0.7}``` for the 'RB' agent\n",
    "    - ```{'learning_rate':0.5}``` for the 'QL' agent\n",
    "    - the default parameters (i.e., empty dictionary) for all other agent types\n",
    "\n",
    "Once you've created your ```group``` object, print it and inspect it, using ```print(group)``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8c57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T07:09:04.880519Z",
     "start_time": "2022-09-20T07:09:04.876514Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8505211",
   "metadata": {},
   "source": [
    "You can inspect the further functionality of the ```AgentGroup``` class using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd79d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T07:05:12.966586Z",
     "start_time": "2022-09-20T07:05:12.934363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AgentGroup in module tomsup.agent:\n",
      "\n",
      "class AgentGroup(builtins.object)\n",
      " |  AgentGroup(agents: List[str], start_params: Union[List[dict], NoneType] = None)\n",
      " |  \n",
      " |  An agent group is a group of agents. It is a utility class to allow for\n",
      " |  easily setting up tournaments.\n",
      " |  \n",
      " |  Examples:\n",
      " |      >>> round_table = AgentGroup(agents=['RB']*2,             start_params=[{'bias': 1}]*2)\n",
      " |      >>> round_table.agent_names\n",
      " |      ['RB_0', 'RB_1']\n",
      " |      >>> RB_0 = round_table.get_agent('RB_0') # extract an agent\n",
      " |      >>> RB_0.bias == 1 # should naturally be 1, as we specified it\n",
      " |      True\n",
      " |      >>> round_table.set_env('round_robin')\n",
      " |      >>> result = round_table.compete(p_matrix=\"penny_competitive\",             n_rounds=100, n_sim=10)\n",
      " |      Currently the pair, ('RB_0', 'RB_1'), is competing for 10 simulations,             each containg 100 rounds.\n",
      " |          Running simulation 1 out of 10\n",
      " |          Running simulation 2 out of 10\n",
      " |          Running simulation 3 out of 10\n",
      " |          Running simulation 4 out of 10\n",
      " |          Running simulation 5 out of 10\n",
      " |          Running simulation 6 out of 10\n",
      " |          Running simulation 7 out of 10\n",
      " |          Running simulation 8 out of 10\n",
      " |          Running simulation 9 out of 10\n",
      " |          Running simulation 10 out of 10\n",
      " |      Simulation complete\n",
      " |      >>> result.shape[0] == 10*100 # As there is 10 simulations each containing                                        100 round\n",
      " |      True\n",
      " |      >>> result['payoff_agent0'].mean() == 1  # Given that both agents have             always choose 1, it is clear that agent0 always win, when playing the             competitive pennygame\n",
      " |      True\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, agents: List[str], start_params: Union[List[dict], NoneType] = None)\n",
      " |      Args:\n",
      " |          agents (List[str]): A list of agents\n",
      " |          start_params (Optional[List[dict]], optional): The starting parameters of the agents specified\n",
      " |              as a dictionary pr. agent. Defaults to None, indicating default for all agent. Use empty to\n",
      " |              use default of an agent.\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  compete(self, p_matrix: tomsup.payoffmatrix.PayoffMatrix, n_rounds: int = 10, n_sim: int = 1, reset_agent: bool = True, env: Union[str, NoneType] = None, save_history: bool = False, verbose: bool = True, n_jobs: Union[int, NoneType] = None) -> pandas.core.frame.DataFrame\n",
      " |      for each pair competes using the specified parameters\n",
      " |      \n",
      " |      Args:\n",
      " |          p_matrix (PayoffMatrix): The payoffmatrix in which the agents compete\n",
      " |          n_rounds (int, optional): Number of rounds the agent should play in each simulation.\n",
      " |              Defaults to 10.\n",
      " |          n_sim (int, optional): The number of simulations. Defaults to 1.\n",
      " |          reset_agent (bool, optional): Should the agent be reset ? Defaults to True.\n",
      " |          env (Optional[str], optional): The environment in which the agent should compete.\n",
      " |              Defaults to None, indicating the already set environment.\n",
      " |          save_history (bool, optional): Should the history of agent be saved.\n",
      " |              Defaults to False, as this is memory intensive.\n",
      " |          verbose (bool, optional): Toggles the verbosity of the function. Defaults to True.\n",
      " |          n_jobs (Optional[int], optional): Number of parallel jobs. Defaults to None, indicating no parallelization.\n",
      " |              -1 indicate as many jobs as there is cores on your unit.\n",
      " |      \n",
      " |      Returns:\n",
      " |          pd.DataFrame: A pandas dataframe of the results.\n",
      " |  \n",
      " |  get_agent(self, agent: str) -> tomsup.agent.Agent\n",
      " |  \n",
      " |  get_environment(self)\n",
      " |      Returns:\n",
      " |          the pairing resulted from the set environment\n",
      " |  \n",
      " |  get_environment_name(self) -> str\n",
      " |      Returns:\n",
      " |          str: The name of the set environment\n",
      " |  \n",
      " |  get_names(self) -> List[str]\n",
      " |      Returns:\n",
      " |          List[str]: the names of the agents\n",
      " |  \n",
      " |  get_results(self) -> pandas.core.frame.DataFrame\n",
      " |      Returns:\n",
      " |          pd.DataFrame: The results\n",
      " |  \n",
      " |  plot_choice(self, agent0: str, agent1: str, agent: int = 0, sim: Union[int, NoneType] = None, plot_individual_sim: bool = False, show: bool = True)\n",
      " |      plots the choice of an agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          plot_individual_sim (bool, optional): Should you plot each individual simulation. Defaults to False.\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_heatmap(self, aggregate_col: str = 'payoff_agent', aggregate_fun: Callable = <function mean at 0x7fa913f83830>, certainty_fun: Union[Callable, str] = 'mean_ci_95', cmap: str = 'Blues', na_color: str = 'xkcd:white', xlab: str = 'Agent', ylab: str = 'Opponent', cbarlabel: str = 'Average score of the agent', show: bool = True)\n",
      " |      plot a heatmap of the results.\n",
      " |      \n",
      " |      Args:\n",
      " |          aggregate_col (str, optional): The column to aggregate on. Defaults to \"payoff_agent\".\n",
      " |          aggregate_fun (Callable, optional): The function to aggregate by. Defaults to np.mean.\n",
      " |          certainty_fun (Union[Callable, str], optional): The certainty function specified as a string on\n",
      " |              the form \"mean_ci_X\" where X denote the confidence interval, or a function.\n",
      " |              Defaults to \"mean_ci_95\".\n",
      " |          cmap (str, optional): The color map. Defaults to \"Blues\".\n",
      " |          na_color (str, optional): The color of NAs. Defaults to \"xkcd:white\", e.g. white.\n",
      " |          xlab (str, optional): The name on the x-axis. Defaults to \"Agent\".\n",
      " |          ylab (str, optional): The name of the y-axis. Defaults to \"Opponent\".\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_history(self, agent0: int, agent1: int, state: str, agent: int = 0, fun: Callable = <function AgentGroup.<lambda> at 0x7fa917f97b00>, ylab: str = '', xlab: str = 'Round', show: bool = True)\n",
      " |      Plots the history of an agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          state (str):  The state of the agent you wish to plot.\n",
      " |          fun (Callable, optional): A function for extracting the state. Defaults to lambdax:x[state].\n",
      " |          xlab (str, optional): The name on the x-axis. Defaults to \"Agent\".\n",
      " |          ylab (str, optional): The name of the y-axis. Defaults to \"Opponent\".\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_op_states(self, agent0: str, agent1: str, state: str, level: int = 0, agent: int = 0, show: bool = True)\n",
      " |      plots the p_self of a k-ToM agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          state (str): a state of the simulated opponent you wish to plot.\n",
      " |          level (str): level of the similated opponent you wish to plot.\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_p_k(self, agent0: str, agent1: str, level: int, agent: int = 0, show: bool = True)\n",
      " |      plots the p_k of a k-ToM agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_p_op_1(self, agent0: str, agent1: str, agent: int = 0, show: bool = True) -> None\n",
      " |      plots the p_op_1 of a k-ToM agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_p_self(self, agent0: str, agent1: str, agent: int = 0, show: bool = True)\n",
      " |      plots the p_self of a k-ToM agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_score(self, agent0: str, agent1: str, agent: int = 0, show: bool = True)\n",
      " |      plots the score of an agent in a defined agent pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  plot_tom_op_estimate(self, agent0: int, agent1: int, level: int, estimate: str, agent: int = 0, plot: str = 'mean', transformation: Union[bool, NoneType] = None, show: bool = True)\n",
      " |      plot a k-ToM's estimates the opponent in a given pair\n",
      " |      \n",
      " |      Args:\n",
      " |          agent0 (str): The name of agent0\n",
      " |          agent1 (str): The name of agent1\n",
      " |          agent (int, optional): An int denoting which of agent 0 or 1 you should plot. Defaults to 0.\n",
      " |          estimate (str): The desired estimate to plot options include:\n",
      " |             \"volatility\",\n",
      " |             \"behav_temp\" (Behavoural Temperature),\n",
      " |             \"bias\",\n",
      " |             \"dilution\".\n",
      " |          level (str): Sophistication level of the similated opponent you wish to plot.\n",
      " |          plot (str, optional): Toggle between plotting mean (\"mean\") or variance (\"var\"). Default to \"mean\".\n",
      " |          show (bool, optional): Should plt.show be run at the end. Defaults to True.\n",
      " |  \n",
      " |  set_env(self, env: str) -> None\n",
      " |      Set environment of the agent group.\n",
      " |      \n",
      " |      Args:\n",
      " |          env (str): The string for the environment you wish to set.\n",
      " |              Valid environment strings include:\n",
      " |              'round_robin': Matches all participant against all others\n",
      " |              'random_pairs': Combines the agent in random pairs (the number of\n",
      " |              agent must be even)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ts.AgentGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503851d7",
   "metadata": {},
   "source": [
    "**Setting the type of interaction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd388077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6086959e",
   "metadata": {},
   "source": [
    "**Exercise 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc21dbf",
   "metadata": {},
   "source": [
    "# BELOW ARE THE ENVISIONED ANSWERS TO EACH EXERCISE (FOR LAURA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b390a",
   "metadata": {},
   "source": [
    "**Envisioned answer to exercise 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6b3835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:22:18.609813Z",
     "start_time": "2022-09-20T00:22:18.587707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PayoffMatrix in module tomsup.payoffmatrix:\n",
      "\n",
      "class PayoffMatrix(builtins.object)\n",
      " |  PayoffMatrix(name: str, predefined: Union[<built-in function array>, NoneType] = None)\n",
      " |  \n",
      " |  A class of 2 by 2 payoff matrices.\n",
      " |  \n",
      " |  Currently include the following games:\n",
      " |  The staghunt game: 'staghunt',\n",
      " |  The matching pennies game (coop and competive): 'penny_competive', 'penny_cooperative',\n",
      " |  The party dilemma: 'party',\n",
      " |  The Battle of the sexes: 'sexes',\n",
      " |  The chicken game: 'chicken',\n",
      " |  The deadlock: 'deadlock',\n",
      " |  The prisoners dilemma: 'prisoners_dilemma'.\n",
      " |  \n",
      " |  For custom payoff matrix supply a 2x2x2 numpy array to the predefined argument.\n",
      " |  \n",
      " |  Examples:\n",
      " |      >>> import tomsup as ts\n",
      " |      >>> staghunt = ts.PayoffMatrix(name=\"staghunt\")\n",
      " |      >>> staghunt.payoff(action_agent0=1, action_agent1=1, agent=0)\n",
      " |      5\n",
      " |      >>> staghunt.payoff(action_agent0=1, action_agent1=0, agent=0)\n",
      " |      0\n",
      " |      >>> staghunt.payoff(action_agent0=0, action_agent1=1, agent=0)\n",
      " |      3\n",
      " |      >>> chicken = ts.PayoffMatrix(name=\"chicken\")\n",
      " |      >>> chicken.payoff(0, 1, 0)\n",
      " |      -1\n",
      " |      >>> dead = ts.PayoffMatrix(name=\"deadlock\")\n",
      " |      >>> dead.payoff(1, 0, 1)\n",
      " |      0\n",
      " |      >>> sexes = ts.PayoffMatrix(name=\"sexes\")\n",
      " |      >>> sexes.payoff(1, 1, 0)\n",
      " |      5\n",
      " |      >>> custom = ts.PayoffMatrix(name=\"custom\", np.array(([(10, 0), (0, 5)],\n",
      " |                                                      [(5, 0), (0, 10)])))\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, name: str, predefined: Union[<built-in function array>, NoneType] = None)\n",
      " |      Args:\n",
      " |          name (str): The name of the either predefined matrix or your custom matrix.\n",
      " |              Currently include the following games:\n",
      " |              The staghunt game ('staghunt'),\n",
      " |              the matching pennies game ('penny_competive', 'penny_cooperative'),\n",
      " |              the party dilemma ('party'),\n",
      " |              the Battle of the sexes ('sexes'), the chicken game ('chicken'),\n",
      " |              the deadlock ('deadlock'), nad the prisoners dilemma ('prisoners_dilemma').\n",
      " |          predefined (Optional[np.array], optional): A custom 2x2x2 matrix. Defaults to None.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  get_matrix(self) -> <built-in function array>\n",
      " |      Returns:\n",
      " |          np.array: The payoff matrix\n",
      " |  \n",
      " |  payoff(self, choice_agent0: int, choice_agent1: int, agent: int = 0) -> float\n",
      " |      Args:\n",
      " |          choice_agent0 (int): choice of agent 0\n",
      " |          choice_agent1 (int): choice of agent 1\n",
      " |          agent (int, optional): The perspective agent which should get the payoff, either 0 or 1.\n",
      " |              Defaults to 0.\n",
      " |      \n",
      " |      Returns:\n",
      " |          float: The payoff of the agent\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ts.PayoffMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55ba622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T06:12:11.810642Z",
     "start_time": "2022-09-20T06:12:11.775638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Class PayoffMatrix, Name = staghunt> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |   | 0 | 1 |\n",
      "       | --------- |\n",
      "Choice | 0 | 3 | 3 |\n",
      "agent 0| 1 | 0 | 5 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |   | 0 | 1 |\n",
      "       | --------- |\n",
      "Choice | 0 | 3 | 0 |\n",
      "agent 0| 1 | 3 | 5 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = penny_competitive> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 | -1 |  1 |\n",
      "agent 0|  1 |  1 | -1 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  1 | -1 |\n",
      "agent 0|  1 | -1 |  1 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = penny_cooperative> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  1 | -1 |\n",
      "agent 0|  1 | -1 |  1 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  1 | -1 |\n",
      "agent 0|  1 | -1 |  1 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = party> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  5 |  0 |\n",
      "agent 0|  1 |  0 | 10 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  5 |  0 |\n",
      "agent 0|  1 |  0 | 10 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = sexes> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 | 10 |  0 |\n",
      "agent 0|  1 |  0 |  5 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |    |  0 |  1 |\n",
      "       | ------------ |\n",
      "Choice |  0 |  5 |  0 |\n",
      "agent 0|  1 |  0 | 10 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = chicken> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |       |     0 |     1 |\n",
      "       | --------------------- |\n",
      "Choice |     0 | -1000 |    -1 |\n",
      "agent 0|     1 |     1 |     0 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |       |     0 |     1 |\n",
      "       | --------------------- |\n",
      "Choice |     0 | -1000 |     1 |\n",
      "agent 0|     1 |    -1 |     0 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = deadlock> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |   | 0 | 1 |\n",
      "       | --------- |\n",
      "Choice | 0 | 1 | 0 |\n",
      "agent 0| 1 | 3 | 2 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |   | 0 | 1 |\n",
      "       | --------- |\n",
      "Choice | 0 | 1 | 3 |\n",
      "agent 0| 1 | 0 | 2 |\n",
      " \n",
      "\n",
      "<Class PayoffMatrix, Name = prisoners_dilemma> \n",
      "The payoff matrix of agent 0\n",
      "       |  Choice agent 1\n",
      "       |   | 0 | 1 |\n",
      "       | --------- |\n",
      "Choice | 0 | 1 | 5 |\n",
      "agent 0| 1 | 0 | 3 |\n",
      " \n",
      "The payoff matrix of agent 1\n",
      "       |  Choice agent 1\n",
      "       |   | 0 | 1 |\n",
      "       | --------- |\n",
      "Choice | 0 | 1 | 0 |\n",
      "agent 0| 1 | 5 | 3 |\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first let's create a list of all game names that are predefined according to help(ts.PayoffMatrix):\n",
    "games = ['staghunt', 'penny_competitive', 'penny_cooperative', 'party', 'sexes', 'chicken', 'deadlock', 'prisoners_dilemma']\n",
    "\n",
    "# now let's loop through the games and print each one, using the ts.PayoffMatrix() class:\n",
    "for game in games:\n",
    "    print(ts.PayoffMatrix(name=game))\n",
    "    print('') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff441e2",
   "metadata": {},
   "source": [
    "- staghunt is cooperative because the cell in the pay-off matrix where the two agents get the highest pay-off is the same for both agents (i.e., when they both choose action 1.\n",
    "\n",
    "- penny_competitive is competitive in nature because the pay-off matrices for the two agents are each others' mirror image.\n",
    "\n",
    "- penny_cooperative is cooperative in nature because the pay-off matrices of the two agents are identical.\n",
    "\n",
    "- party is cooperative because the pay-off matrices of the two agents are identical\n",
    "\n",
    "- sexes is competitive in nature, because the cells in which the agents get the highest pay-off are each other's mirror image\n",
    "\n",
    "- chicken is competitive because the cells in which the agents get the highest pay-off are each other's mirror image. However, there is also a very high cost for both agents if neither of them \"yields\" (i.e., chooses action 1)\n",
    "\n",
    "- deadlock is competitive because the cells in which the agents get the highest pay-off are each other's mirror image\n",
    "\n",
    "- prisoners_dilemma is competitive because the cells in which the agents get the highest pay-off are each other's mirror image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb826293",
   "metadata": {},
   "source": [
    "**Envisioned answer to exercise 2:**\n",
    "\n",
    "No, there are no other examples of zero-sum games among the predefined games in the package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce33bbf",
   "metadata": {},
   "source": [
    "**Envisioned answer to exercise 3:**\n",
    "\n",
    "party is another example: When both agents are in the state of choosing action 0, this is suboptimal (they would both be better off if they each chose action 1). However, if either agent chooses to change strategy to action 1 individually this will decrease their pay-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdbe75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
